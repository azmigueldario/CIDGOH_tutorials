{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113df914-b625-46a3-8b82-f522c98f48d8",
   "metadata": {},
   "source": [
    "# Genome assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ff02db-aca0-4676-9da3-330584a10d49",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Required tools\n",
    "\n",
    "After the previous steps of quality control (QC), we have reads still in raw_format but now we have a summary of their quality. Furthermore, we have removed regions with poor quality of sequencing (where we cannot be sure if the assigned nucleotides are right) and we removed the adaptor sequences that are added to our DNA for sequencing. \n",
    "\n",
    "In this series of steps, we will do assembly of the reads using a tool called `shovill`. Once again, we will mimic how to run the commands in the **Compute Canada (CC)** cluster of analysis. \n",
    "\n",
    "For these tutorials, tools will be made available using singularity containers, which can be run using the command `singularity run tool_image`. These tools have been made available in the environment already, so there is no need to download them.\n",
    "\n",
    "Tools used in this tutorial:\n",
    "- shovill\n",
    "- singularity\n",
    "\n",
    "We will first explore the structure of our environment and the folders available. Tools downloaded for the tutorial are in the `tools` folder and in the `tutorials` directory are the primary datasets as well as the results of our runs. \n",
    "\n",
    "```\n",
    ".\n",
    "|-- tools\n",
    "`-- tutorials\n",
    "    |-- raw_reads\n",
    "    |-- results_qc\n",
    "    `-- trimmed_reads\n",
    "```\n",
    "\n",
    "For downstream assembly, we will use the curated reads contained in the `trimmed_reads` subdirectory (n=20 files containing paired reads for 10 isolates of _P.aeruginosa_). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "496d090f-da9d-4813-a2d7-e0e8d163d1c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# source PATH to use module function\n",
    "source /cvmfs/soft.computecanada.ca/config/profile/bash.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7787d504-aa7f-47d3-b3c7-00308ecf43c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR10479510_R1.fastq.gz  ERR10479513_R2.fastq.gz  ERR10479517_R1.fastq.gz\n",
      "ERR10479510_R2.fastq.gz  ERR10479514_R1.fastq.gz  ERR10479517_R2.fastq.gz\n",
      "ERR10479511_R1.fastq.gz  ERR10479514_R2.fastq.gz  ERR10479518_R1.fastq.gz\n",
      "ERR10479511_R2.fastq.gz  ERR10479515_R1.fastq.gz  ERR10479518_R2.fastq.gz\n",
      "ERR10479512_R1.fastq.gz  ERR10479515_R2.fastq.gz  ERR10479519_R1.fastq.gz\n",
      "ERR10479512_R2.fastq.gz  ERR10479516_R1.fastq.gz  ERR10479519_R2.fastq.gz\n",
      "ERR10479513_R1.fastq.gz  ERR10479516_R2.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "cd\n",
    "ls tutorials/trimmed_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a79a81-00a5-4cc9-9a72-dab9f7c26fd4",
   "metadata": {},
   "source": [
    "## De-novo assembly with Shovill\n",
    "\n",
    "Shovill is a tool that optimizes the assembler `Spades` to minimize the run time, while maintaining the quality of assembly. It generates a draft genome using heuristic algorithms and does not require a reference genome that guides the process. See the GitHub repositories of [shovill](https://github.com/tseemann/shovill) and [SPAdes](https://github.com/ablab/spades) for more details. \n",
    "\n",
    "Shovill is not available as a module pre-installed in **CC**, so we must use another strategy. The easiest one is to use a container, we can install from a **Docker** container, but Docker containers are not suitable for high performance clusters like **Compute Canada** because they have inherent root user privileges. Thus, many HPC allow use of **Singularity** images as an alternative (For more info about what is containerization you can read https://www.melbournebioinformatics.org.au/tutorials/tutorials/docker/docker/).\n",
    "\n",
    "A useful repository of **Singularity** images is located at https://depot.galaxyproject.org/singularity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0295f341-5926-4e79-91c9-d98631079b29",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lmod has detected the following error: The following module(s) are unknown:\n",
      "\"singularity\"\n",
      "\n",
      "Please check the spelling or version number. Also try \"module spider ...\"\n",
      "It is also possible your cache file is out-of-date; it may help to try:\n",
      "  $ module --ignore_cache load \"singularity\"\n",
      "\n",
      "Also make sure that all modulefiles written in TCL start with the string\n",
      "#%Module\n",
      "\n",
      "\n",
      "\n",
      "SYNOPSIS\n",
      "  De novo assembly pipeline for Illumina paired reads\n",
      "USAGE\n",
      "  shovill [options] --outdir DIR --R1 R1.fq.gz --R2 R2.fq.gz\n",
      "GENERAL\n",
      "  --help          This help\n",
      "  --version       Print version and exit\n",
      "  --check         Check dependencies are installed\n",
      "INPUT\n",
      "  --R1 XXX        Read 1 FASTQ (default: '')\n",
      "  --R2 XXX        Read 2 FASTQ (default: '')\n",
      "  --depth N       Sub-sample --R1/--R2 to this depth. Disable with --depth 0 (default: 150)\n",
      "  --gsize XXX     Estimated genome size eg. 3.2M <blank=AUTODETECT> (default: '')\n",
      "OUTPUT\n",
      "  --outdir XXX    Output folder (default: '')\n",
      "  --force         Force overwite of existing output folder (default: OFF)\n",
      "  --minlen N      Minimum contig length <0=AUTO> (default: 0)\n",
      "  --mincov n.nn   Minimum contig coverage <0=AUTO> (default: 2)\n",
      "  --namefmt XXX   Format of contig FASTA IDs in 'printf' style (default: 'contig%05d')\n",
      "  --keepfiles     Keep intermediate files (default: OFF)\n",
      "RESOURCES\n",
      "  --tmpdir XXX    Fast temporary directory (default: '')\n",
      "  --cpus N        Number of CPUs to use (0=ALL) (default: 8)\n",
      "  --ram n.nn      Try to keep RAM usage below this many GB (default: 16)\n",
      "ASSEMBLER\n",
      "  --assembler XXX Assembler: velvet spades skesa megahit (default: 'spades')\n",
      "  --opts XXX      Extra assembler options in quotes eg. spades: '--sc' (default: '')\n",
      "  --kmers XXX     K-mers to use <blank=AUTO> (default: '')\n",
      "MODULES\n",
      "  --trim          Enable adaptor trimming (default: OFF)\n",
      "  --noreadcorr    Disable read error correction (default: OFF)\n",
      "  --nostitch      Disable read stitching (default: OFF)\n",
      "  --nocorr        Disable post-assembly correction (default: OFF)\n",
      "HOMEPAGE\n",
      "  https://github.com/tseemann/shovill - Torsten Seemann\n"
     ]
    }
   ],
   "source": [
    "# pull the container with shovill\n",
    "# singularity pull tools/shovill_1.1.sif https://depot.galaxyproject.org/singularity/shovill%3A1.1.0--hdfd78af_1\n",
    "\n",
    "# help for the command\n",
    "module load singularity\n",
    "singularity exec tools/shovill_1.1.sif shovill --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba8b22-fddf-4774-b9d0-5c0fb23a33ae",
   "metadata": {},
   "source": [
    "#### What does shovill do?\n",
    "\n",
    "1. Unifies coverage depth for all genomes\n",
    "2. Trims adapters and poor quality reads if necessary\n",
    "3. Assembles using SPAdes\n",
    "4. Polishes genomes (improves quality) and filters low quality contigs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b145e909-c993-46e8-bf8f-ac42000e5bf2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create output directory\n",
    "mkdir -p /home/jupyter-mdprieto/tutorials/assemblies\n",
    "OUTPUT_DIR_TUTORIAL=\"/home/jupyter-mdprieto/tutorials/assemblies\"\n",
    "\n",
    "# define PATH to trimmed_reads\n",
    "TRIMMED_READS=\"/home/jupyter-mdprieto/tutorials/trimmed_reads\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858935a0-b97d-4969-aeae-88b3885a5df4",
   "metadata": {},
   "source": [
    "To execute shovill, we run the command from the singularity container we just downloaded. Genome assembly is the most resource intensive process in the pipeline, so it will probably take a while to run. As input, we will use or `trimmed_reads` files and to optimize your run time, we will assemble only two isolates. The remaining ones are already available in the `tutorials/results` folder\n",
    "\n",
    "<font color='darkred'>_**Notes for compute canada:**_ </font>  \n",
    "- Allocate sufficiente memory as the size of every genome must be kept in storage while it is assembled\n",
    "- Bioinformatic procedures usually use multiple threads to optimize performance, so their efficiency increases with the number of available cores (including **SPAdes**). \n",
    "- In shovill, the `--ram` option specifies the available ram per thread (core)\n",
    "    - Spades will take input of RAM from shovill as total available mem, better to input limit manually with `--opts \"-m XX\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd2617-1bd2-4d19-9c44-f617d4e9a8c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[spades]   0:00:21.720   133M / 5G    INFO [shovill] Error 33280 running command: Inappropriate ioctl for device\n",
      "mv: cannot stat '/home/jupyter-mdprieto/tutorials/assemblies/contigs.fa': No such file or directory\n",
      "/opt/tljh/user/bin/bash: Finished: command not foundassembly: command not foundof: command not foundsample: command not found\n"
     ]
    }
   ],
   "source": [
    "for read1 in $(ls $TRIMMED_READS/*R1.fastq.gz | head -n 2)\n",
    "do\n",
    "\n",
    "    # substitute R1 for R2 in variable\n",
    "    read2=${read1/_R1/_R2}\n",
    "    # extract isolate id\n",
    "    prefix_isolate=$(basename $read1 _R1.fastq.gz)\n",
    "    echo $read2 $prefix_isolate $ read1\n",
    "    \n",
    "    echo singularity exec -B /scratch tools/shovill_1.1.sif shovill \\\n",
    "    --R1 $read1 --R2 $read2 \\\n",
    "    --outdir $OUTPUT_DIR_TUTORIAL \\\n",
    "    --opts \"-s $trimmed\" \\\n",
    "    --ram 140;\n",
    "    \n",
    "    # name resulting file with isolate id\n",
    "    echo mv contigs.fa $prefix_isolate\\_contigs.fa\n",
    "    \n",
    "    echo \"Finished assembly of sample\"\n",
    "    echo\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b71de2-4acc-47c9-bcf2-9b3892fd47d5",
   "metadata": {},
   "source": [
    "The main output of the **Shovill** pipeline are the files ending in `contigs.fa` which contain assembled reads in fasta format. We can see that this format contains a header for every contig and then the reads.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eacd90-b635-49c7-b907-0729c900b3d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "[shovill] Hello jupyter-mdprieto\n",
      "[shovill] You ran: /usr/local/bin/shovill --R1 /home/jupyter-mdprieto/tutorials/trimmed_reads/ERR10479510_R1.fastq.gz --R2 /home/jupyter-mdprieto/tutorials/trimmed_reads/ERR10479510_R2.fastq.gz --outdir /home/jupyter-mdprieto/tutorials/assemblies --force --ram 140\n",
      "[shovill] This is shovill 1.1.0\n",
      "[shovill] Written by Torsten Seemann\n",
      "[shovill] Homepage is https://github.com/tseemann/shovill\n",
      "[shovill] Operating system is linux\n",
      "[shovill] Perl version is v5.26.2\n",
      "[shovill] Machine has 16 CPU cores and 176.90 GB RAM\n",
      "[shovill] Using bwa - /usr/local/bin/bwa | Version: 0.7.17-r1188\n",
      "[shovill] Using flash - /usr/local/bin/flash | FLASH v1.2.11\n",
      "[shovill] Using java - /usr/local/bin/java | openjdk version \"11.0.1\" 2018-10-16 LTS\n",
      "[shovill] Using kmc - /usr/local/bin/kmc | K-Mer Counter (KMC) ver. 3.1.1 (2019-05-19)\n",
      "[shovill] Using lighter - /usr/local/bin/lighter | Lighter v1.1.2\n",
      "[shovill] Using megahit - /usr/local/bin/megahit | MEGAHIT v1.2.9\n",
      "[shovill] Using megahit_toolkit - /usr/local/bin/megahit_toolkit | v1.2.9\n",
      "[shovill] Using pigz - /usr/local/bin/pigz | pigz 2.6\n",
      "[shovill] Using pilon - /usr/local/bin/pilon | Pilon version 1.23 Mon Nov 26 16:04:05 2018 -0500\n",
      "[shovill] Using samclip - /usr/local/bin/samclip | samclip 0.4.0\n",
      "[shovill] Using samtools - /usr/local/bin/samtools | Version: 1.12 (using htslib 1.12)\n",
      "[shovill] Using seqtk - /usr/local/bin/seqtk | Version: 1.3-r106\n",
      "[shovill] Using skesa - /usr/local/bin/skesa | SKESA 2.4.0\n",
      "[shovill] Using spades.py - /usr/local/bin/spades.py | SPAdes genome assembler v3.14.1\n",
      "[shovill] Using trimmomatic - /usr/local/bin/trimmomatic | 0.39\n",
      "[shovill] Using velvetg - /usr/local/bin/velvetg | Version 1.2.10\n",
      "[shovill] Using velveth - /usr/local/bin/velveth | Version 1.2.10\n",
      "[shovill] Found spades version: 003014000\n",
      "[shovill] Will use spades 003014000 options: --isolate and --merged\n",
      "[shovill] Forced overwrite of existing --outdir /home/jupyter-mdprieto/tutorials/assemblies\n",
      "[shovill] Using tempdir: /tmp/RGBlkY1Qkc\n",
      "[shovill] Changing into folder: /home/jupyter-mdprieto/tutorials/assemblies\n",
      "[shovill] Collecting raw read statistics with 'seqtk'\n",
      "[shovill] Running: seqtk fqchk -q3 \\/home\\/jupyter\\-mdprieto\\/tutorials\\/trimmed_reads\\/ERR10479510_R1\\.fastq\\.gz >/tmp/UgNBZmGmdw 2>&1 | sed 's/^/[seqtk] /' | tee -a shovill.log\n",
      "[shovill] Read stats: max_len = 251\n",
      "[shovill] Read stats: min_len = 35\n",
      "[shovill] Read stats: total_bp = 771604434\n",
      "[shovill] Read stats: avg_len = 231\n",
      "[shovill] Estimating genome size by counting unqiue 21-mers > frequency 10 \n",
      "[shovill] Running: kmc -sm -m70 -t8 -k21 -ci10 \\/home\\/jupyter\\-mdprieto\\/tutorials\\/trimmed_reads\\/ERR10479510_R1\\.fastq\\.gz /tmp/emGfOiA8GM/kmc /tmp/emGfOiA8GM 2>&1 | sed 's/^/[kmc] /' | tee -a shovill.log\n"
     ]
    }
   ],
   "source": [
    "for read1 in $(ls $TRIMMED_READS/*R1.fastq.gz | head -n 2)\n",
    "do\n",
    "\n",
    "    # substitute R1 for R2 in variable\n",
    "    read2=${read1/_R1/_R2}\n",
    "    # extract isolate id\n",
    "    prefix_isolate=$(basename $read1 _R1.fastq.gz)\n",
    "    echo 'started'\n",
    "    \n",
    "    singularity exec tools/shovill_1.1.sif shovill --R1 $read1 --R2 $read2 \\\n",
    "    --outdir $OUTPUT_DIR_TUTORIAL \\\n",
    "    --force \\\n",
    "    --ram 140 \n",
    "    \n",
    "    # name resulting file with isolate id\n",
    "    mv $OUTPUT_DIR_TUTORIAL/contigs.fa $OUTPUT_DIR_TUTORIAL/$prefix_isolate\\_contigs.fa\n",
    "    \n",
    "    \"Finished assembly of sample\"\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c36552e-64da-4711-b61e-d75cb95e3155",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for R1 in $(ls $TRIMMED_READS/*R1*fastq.gz)\n",
    "\n",
    "do\n",
    "    # create environment variables for R2 and R0 files and establish a name for the output directory\n",
    "    file2=${file1/R1/R2}\n",
    "    trimmed=${file1/R1/R0}\n",
    "    out_dir_sample=$(echo $file1 | grep -oE '[0-9]{1,3}-[ABC][0-9]*')\n",
    "\n",
    "    # ------ Execute shovill inside singularity container\n",
    "    # --opts = options to pass into spades assembler\n",
    "    # --ram = total ram in all CPUs\n",
    "\n",
    "    singularity exec $BIND_MOUNT shovill.sif shovill --R1 $file1 --R2 $file2 \\\n",
    "    --outdir $OUTPUT_DIR/$out_dir_sample \\\n",
    "    --opts \"-s $trimmed\" \\\n",
    "    --cpus $SLURM_CPUS_PER_TASK \\\n",
    "    --ram 140 \\\n",
    "    --tmpdir /scratch/mdprieto/tmp\n",
    "    echo \"Finished assembly of sample\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09196f5d-98c8-4aef-938c-275f4190ebdf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mkdir -p /home/jupyter-mdprieto/tutorials/assemblies\n",
    "\n",
    "# mount my filesystem inside container\n",
    "# ---------- localscratch is defined to use compute node temp folder\n",
    "-B /scratch,/localscratch,/localscratch:/temp\n",
    "\n",
    "# create variables and output dir\n",
    "mkdir -p /scratch/mdprieto/results_hilliam/shovill\n",
    "OUTPUT_DIR=\"/scratch/mdprieto/results_hilliam/shovill\"\n",
    "INPUT_DIR=\"/project/6056895/mdprieto/hilliam_pseudomonas/bronchiectasis_reads\"\n",
    "\n",
    "################################## shovill #########################################\n",
    "\n",
    "for file1 in $(ls $INPUT_DIR/*R1*fastq.gz)\n",
    "\n",
    "do\n",
    "    # create environment variables for R2 and R0 files and establish a name for the output directory\n",
    "    file2=${file1/R1/R2}\n",
    "    trimmed=${file1/R1/R0}\n",
    "    out_dir_sample=$(echo $file1 | grep -oE '[0-9]{1,3}-[ABC][0-9]*')\n",
    "\n",
    "    # ------ Execute shovill inside singularity container\n",
    "    # --opts = options to pass into spades assembler\n",
    "    # --ram = total ram in all CPUs\n",
    "\n",
    "    singularity exec $BIND_MOUNT shovill.sif shovill --R1 $file1 --R2 $file2 \\\n",
    "    --outdir $OUTPUT_DIR/$out_dir_sample \\\n",
    "    --opts \"-s $trimmed\" \\\n",
    "    --cpus $SLURM_CPUS_PER_TASK \\\n",
    "    --ram 140 \\\n",
    "    --tmpdir /scratch/mdprieto/tmp\n",
    "    echo \"Finished assembly of sample\"\n",
    "done\n",
    "\n",
    "######################## create new dir with assemblies #############################\n",
    "\n",
    "contigs_dir=\"/scratch/mdprieto/results_hilliam/sample_contigs\"\n",
    "\n",
    "# new directory with sample name appended to the contigs\n",
    "# finds 'contigs.fa' filenames downstream\n",
    "# appends 'sample_name' to each 'contigs.fa' in a new folder 'sample_contigs'\n",
    "\n",
    "mkdir -p $contigs_dir\n",
    "for i in `find /scratch/mdprieto/results_hilliam/shovill -name \"contigs.fa\"`\n",
    "   do cp -n $i $contigs_dir/`echo $i| awk -F/ '{print $6 \"_\" $7}' `\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d42b3-d719-46c6-8d7e-b0b3639d2b3a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --account=def-whsiao-ab\n",
    "#SBATCH --mem-per-cpu=12G #  GB of memory per cpu core\n",
    "#SBATCH --time=12:00:00\n",
    "#SBATCH --ntasks=1 # tasks in parallel\n",
    "#SBATCH --cpus-per-task=16 # CPU cores per task\n",
    "#SBATCH --job-name=\"shovill_assembly_hilliam\"\n",
    "#SBATCH --chdir=/scratch/mdprieto/\n",
    "#SBATCH --output=slurm_shovill_16x12.out\n",
    "#SBATCH --mail-user=mprietog@sfu.ca\n",
    "#SBATCH --mail-type=END\n",
    "\n",
    "################################## preparation #########################################\n",
    "\n",
    "# load singularity to execute shovill\n",
    "module purge\n",
    "module load singularity/3.8\n",
    "\n",
    "# mount my filesystem inside container\n",
    "# ---------- localscratch is defined to use compute node temp folder\n",
    "BIND_MOUNT=\"-B /home -B /project -B /scratch -B /localscratch -B /localscratch:/temp\"\n",
    "\n",
    "# create variables and output dir\n",
    "mkdir -p /scratch/mdprieto/results_hilliam/shovill\n",
    "OUTPUT_DIR=\"/scratch/mdprieto/results_hilliam/shovill\"\n",
    "INPUT_DIR=\"/project/6056895/mdprieto/hilliam_pseudomonas/bronchiectasis_reads\"\n",
    "\n",
    "################################## shovill #########################################\n",
    "\n",
    "for file1 in $(ls $INPUT_DIR/*R1*fastq.gz)\n",
    "\n",
    "do\n",
    "    # create environment variables for R2 and R0 files and establish a name for the output directory\n",
    "    file2=${file1/R1/R2}\n",
    "    trimmed=${file1/R1/R0}\n",
    "    out_dir_sample=$(echo $file1 | grep -oE '[0-9]{1,3}-[ABC][0-9]*')\n",
    "\n",
    "    # ------ Execute shovill inside singularity container\n",
    "    # --opts = options to pass into spades assembler\n",
    "    # --ram = total ram in all CPUs\n",
    "\n",
    "    singularity exec $BIND_MOUNT shovill.sif shovill --R1 $file1 --R2 $file2 \\\n",
    "    --outdir $OUTPUT_DIR/$out_dir_sample \\\n",
    "    --opts \"-s $trimmed\" \\\n",
    "    --cpus $SLURM_CPUS_PER_TASK \\\n",
    "    --ram 140 \\\n",
    "    --tmpdir /scratch/mdprieto/tmp\n",
    "    echo \"Finished assembly of sample\"\n",
    "done\n",
    "\n",
    "######################## create new dir with assemblies #############################\n",
    "\n",
    "contigs_dir=\"/scratch/mdprieto/results_hilliam/sample_contigs\"\n",
    "\n",
    "# new directory with sample name appended to the contigs\n",
    "# finds 'contigs.fa' filenames downstream\n",
    "# appends 'sample_name' to each 'contigs.fa' in a new folder 'sample_contigs'\n",
    "\n",
    "mkdir -p $contigs_dir\n",
    "for i in `find /scratch/mdprieto/results_hilliam/shovill -name \"contigs.fa\"`\n",
    "   do cp -n $i $contigs_dir/`echo $i| awk -F/ '{print $6 \"_\" $7}' `\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796bf75a-0373-4cf1-af8e-59b64255ce70",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671584b-1383-4c64-b835-07d7ee16a851",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "```\n",
    "After having the singularity container ready, we can assemble our genomes. \n",
    "\n",
    "\n",
    "### Tips to run assembly jobs on Cedar (CC)\n",
    "\n",
    "- Assembly is a resource intensive job that requires that the data is available in memory for processing. \n",
    "\n",
    "\n",
    "```sh\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "## QC of assembly\n",
    "\n",
    "### Quast \n",
    "\n",
    "We will use QUAST to generate genome assembly metrics. Before running it, we need to download the reference genome for Pseudomonas aeruginosa (PA1). The output directory is specified with the option `-P`\n",
    "\n",
    "```sh\n",
    "\n",
    "# genomic fasta\n",
    "wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/496/605/GCF_000496605.2_ASM49660v2/GCF_000496605.2_ASM49660v2_genomic.fna.gz -P /project/6056895/mdprieto/hilliam_pseudomonas/pseudomonas_pa1_reference\n",
    "\n",
    "# genomic coordinates annotation\n",
    "wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/496/605/GCF_000496605.2_ASM49660v2/GCF_000496605.2_ASM49660v2_genomic.gff.gz -P /project/6056895/mdprieto/hilliam_pseudomonas/pseudomonas_pa1_reference\n",
    "```\n",
    "Now, we run quast with and without reference genome. With reference genome we obtain basic assembly measures and metrics of coverage against the curated assembly. Without a reference, we would obtain only the basic measures. \n",
    "\n",
    "```sh\n",
    "#!/bin/bash\n",
    "#SBATCH --account=def-whsiao-ab\n",
    "#SBATCH --mem-per-cpu=4G #  GB of memory per cpu core\n",
    "#SBATCH --time=00:30:00\n",
    "#SBATCH --ntasks=1 # tasks in parallel\n",
    "#SBATCH --cpus-per-task=8 # CPU cores per task\n",
    "#SBATCH --job-name=\"quast_hilliam\"\n",
    "#SBATCH --chdir=/scratch/mdprieto/\n",
    "#SBATCH --output=quast_hilliam.out\n",
    "\n",
    "###########################################################################\n",
    "\n",
    "# ----------------------- preparation\n",
    "\n",
    "# load QUAST module and dependencies\n",
    "module load StdEnv/2020 gcc/9.3.0 quast/5.0.2\n",
    "\n",
    "# define internal variables\n",
    "genome_fasta=\"/project/6056895/mdprieto/hilliam_pseudomonas/pseudomonas_pa1_reference/GCF_000496605.2_ASM49660v2_genomic.fna.gz\"\n",
    "genome_gff=\"/project/6056895/mdprieto/hilliam_pseudomonas/pseudomonas_pa1_reference/GCF_000496605.2_ASM49660v2_genomic.gff.gz\"\n",
    "contigs_dir=\"/scratch/mdprieto/results_hilliam/sample_contigs\"\n",
    "output_dir=\"/scratch/mdprieto/results_hilliam/quast\"\n",
    "\n",
    "# ----------------------- quast no reference genome\n",
    "\n",
    "quast.py $contigs_dir/*.fa \\\n",
    "\t\t\t-r $genome_fasta \\\n",
    "\t\t\t-g $genome_gff \\\n",
    "\t\t\t-o $output_dir \\\n",
    "\t\t\t--threads 7\n",
    "\n",
    "```\n",
    "\n",
    "### CheckM\n",
    "\n",
    "**CheckM** infers the quality of the genome assembly based on the presence and uniqueness of these sets of gene markers. It determines the completeness (coverage of reference genome) and the contamination of the input draft genomes.\n",
    "\n",
    "**CheckM** is not available in the CC cluster. To install it, we create a virtual environment of python in our home directory. After loading the interpreter, we load the `scipy-stack` module that contains necessary python dependencies (matplotlib and numpy). Also, we load a set of bioinformatic tools dependencies (pplacer, prodigal and hmmer). \n",
    "\n",
    "```sh\n",
    "module load python/3.10.2 scipy-stack\n",
    "module load pplacer/1.1.alpha19 prodigal/2.6.3 hmmer/3.2.1\n",
    "```\n",
    "Is best practice to create virtual environment in your home or project directory. I create `checkm_genome_env` in the home dir; python dependencies are installed after loading environment. The `--no-index` option for python libraries installs those optimized for the compute canada cluster. \n",
    "\n",
    "__CheckM__ requires precalculated data files, which we download to a directory recognized by the tool. \n",
    "\n",
    "```sh\n",
    "cd ~\n",
    "virtualenv --no-download checkm_genome_env\n",
    "\n",
    "source ~/checkm_genome_env/bin/activate\n",
    "pip install --no-index pysam\n",
    "pip install --no-index checkm_genome\n",
    "\n",
    "# unpack precalculated data files\n",
    "mkdir -p /home/mdprieto/checkm_genome_env/data \n",
    "cd /home/mdprieto/checkm_genome_env/data\n",
    "wget https://data.ace.uq.edu.au/public/CheckM_databases/checkm_data_2015_01_16.tar.gz\n",
    "tar -xzf checkm_data_2015_01_16.tar.gz\n",
    "\n",
    "# tell program where data was unpacked\n",
    "export CHECKM_DATA_PATH=/home/mdprieto/checkm_genome_env/data\n",
    "checkm data setRoot /home/mdprieto/checkm_genome_env/data\n",
    "```\n",
    "\n",
    "Run job\n",
    "\n",
    "```sh\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --account=def-whsiao-ab\n",
    "#SBATCH --mem-per-cpu=8G #  GB of memory per cpu core\n",
    "#SBATCH --time=04:00:00\n",
    "#SBATCH --ntasks=1 # tasks in parallel\n",
    "#SBATCH --cpus-per-task=12 # CPU cores per task\n",
    "#SBATCH --job-name=\"assembly_qc_checkm\"\n",
    "#SBATCH --chdir=/scratch/mdprieto/\n",
    "#SBATCH --output=checkm_hilliam.out\n",
    "\n",
    "###################################     preparation ##############################\n",
    "\n",
    "module load python/3.10.2 scipy-stack   # load python dependencies\n",
    "module load pplacer/1.1.alpha19 prodigal/2.6.3 hmmer/3.2.1 # load other dependencies\n",
    "source ~/checkm_genome_env/bin/activate # activate environment with checkm\n",
    "contigs_dir=\"/scratch/mdprieto/results_hilliam/sample_contigs\" # path to dir with assemblies\n",
    "\n",
    "# make dir for results and save PATH into variable\n",
    "mkdir -p /scratch/mdprieto/results_hilliam/checkm\n",
    "output_dir=\"/scratch/mdprieto/results_hilliam/checkm\"\n",
    "\n",
    "# select marker set for P. aeruginosa\n",
    "checkm taxon_set species 'Pseudomonas aeruginosa' $output_dir/pseudomonas.ms\n",
    "date\n",
    "\n",
    "##################################   analyze  #################################\n",
    "\n",
    "# analyze completeness and contamination of 190 assemblies\n",
    "checkm analyze \\\n",
    "        $output_dir/pseudomonas.ms `#file with checkm marker set for assemblies` \\\n",
    "        $contigs_dir `#dir with assemblies in fasta format` \\\n",
    "        $output_dir `#output directory` \\\n",
    "        -x fa `#extension of assemblies` \\\n",
    "        -t 12 `#number of threads for parallel processing`\n",
    "date\n",
    "\n",
    "# produce summary\n",
    "checkm qa \\\n",
    "        $output_dir/pseudomonas.ms `#file with checkm marker set for assemblies` \\\n",
    "        $output_dir `#output directory` \\\n",
    "        --file $output_dir/checkm_output.tsv \\\n",
    "        --tab_table \\\n",
    "        --threads 12\n",
    "date\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## BLAST of pathogen associated genes\n",
    "\n",
    "The pathogen associated genes are stored in a file in the git repo (`burkholderia_pseudomonas_pags.tx`). \n",
    "\n",
    "We use `awk` to extract only the pathogen associated genes (PAGs) of *Pseudomonas* spp. \n",
    "\n",
    "In the code, `NR==1` signals awk to extract the first line with the headers, `$2 ~ /Pseudomonas aeruginosa/ && $5 ~ /pathogen/` matches string to columns, and `-F '\\t'` specifies that the file is tab delimited. We then use cut, tail and sort to extract the accession numbers, eliminate headers and keep only unique identifiers respectively. \n",
    "\n",
    "```sh\n",
    "# change to the git folder with all primary input\n",
    "cd /home/mdprieto/git/hilliam_pseudomonas_2022/\n",
    "\n",
    "awk -F '\\t' 'NR==1 || ( $2 ~ /Pseudomonas/ && $5 ~ /pathogen/)' burkholderia_pseudomonas_pags.txt | \\\n",
    "\tcut -f 3 | \\\n",
    "\ttail -n +2 | \\\n",
    "\tsort -u > accession_pags.txt\n",
    "\n",
    "``` \n",
    "\n",
    "We also use the NCBI e-utilities in order to get the aminoacid sequences for each of the PAGs proteins in fasta format. A collaborator provided two additional fasta files with sequences of proteins of interest, so we add them to our main file before running BLAST.\n",
    "\n",
    "```sh\n",
    "# install ncbi E-utilities in home dir\n",
    "cd ~ | sh -c \"$(curl -fsSL ftp://ftp.ncbi.nlm.nih.gov/entrez/entrezdirect/install-edirect.sh)\"\n",
    "\n",
    "# save unique PAGs in a new txt file\n",
    "/home/mdprieto/edirect/epost \\\n",
    "\t-db protein \\\n",
    "\t-format acc \\\n",
    "\t-input /home/mdprieto/git/hilliam_pseudomonas_2022/accession_pags.txt | \\\n",
    "\t/home/mdprieto/edirect/efetch \\\n",
    "\t-format fasta > /home/mdprieto/git/hilliam_pseudomonas_2022/pags.fasta &\n",
    "\n",
    "```\n",
    "\n",
    "### BLAST PAG in newly assembled genomes\n",
    "\n",
    "In order to run BLAST+ against our assembly files, we need to transform each assembly into a database that can be searched by BLAST. Thus, we create a list of all the contigs files from the resulting assemblies and create a BLAST database for each. Finally, we merge all these databases into a single one using `blastdb_aliastool` \n",
    "\n",
    "```sh\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --account=def-whsiao-ab\n",
    "#SBATCH --mem-per-cpu=10G #  GB of memory per cpu core\n",
    "#SBATCH --time=00:30:00\n",
    "#SBATCH --ntasks=1 # tasks in parallel\n",
    "#SBATCH --cpus-per-task=1 # CPU cores per task\n",
    "#SBATCH --job-name=\"blast_preparation\"\n",
    "#SBATCH --chdir=/scratch/mdprieto/\n",
    "#SBATCH --output=blast_preparation.out\n",
    "\n",
    "###########################################################################\n",
    "################################ preparation\n",
    "\n",
    "# load blast+ module\n",
    "module purge\n",
    "module load StdEnv/2020  gcc/9.3.0 blast+/2.12.0\n",
    "\n",
    "# create pathway variables\n",
    "blast_db=\"/scratch/mdprieto/results_hilliam/blastdb\"\n",
    "contigs_dir=\"/scratch/mdprieto/results_hilliam/sample_contigs\"\n",
    "\n",
    "\n",
    "# ---------------- add isolate ID to each contig\n",
    "# finds sequence headers starting with > and adds the isolate ID before contig\n",
    "\n",
    "cd $contigs_dir\n",
    "for i in `ls $contigs_dir`\n",
    "\tdo\n",
    "\tisolate=$(echo $i | grep -oE '[0-9]{1,3}-[ABC][0-9]*')\n",
    "\techo $isolate\n",
    "\tperl -pi -e \"s/^>/>$isolate\\_/\" $i \n",
    "\thead -n 5 $i\n",
    "\tdone\n",
    "\t\n",
    "grep -oE '[0-9]{1,3}-[ABC][0-9]*'\n",
    "\n",
    "# ---------------- make blast database for each genome\n",
    "\n",
    "# create and move to working directory\n",
    "mkdir -p $blast_db\n",
    "cd $blast_db\n",
    "\n",
    "# create individual databases for each sample_contig\n",
    "for i in `ls $contigs_dir`\n",
    "\tdo \n",
    "\tassembly=\"$contigs_dir/$i\"\n",
    "\techo $assembly\n",
    "\tmakeblastdb \\\n",
    "\t\t-dbtype nucl \\\n",
    "\t\t-in $assembly \\\n",
    "\t\t-out $blast_db/$i.nt \\\n",
    "\t\t-parse_seqids \\\n",
    "\t\t-title \"$i_blast_database\"\n",
    "\tdone\n",
    "\n",
    "# ---------------- create unified database for all sample contigs\n",
    "\n",
    "# lists all blast db in folder with output of path only\n",
    "blastdbcmd -list $blast_db -list_outfmt '%f' > blast_databases.txt \n",
    "\n",
    "# now, given the text file with all databases, it creates a virtual database merging all\n",
    "blastdb_aliastool \\\n",
    "\t-dblist_file $blast_db/blast_databases.txt \\\n",
    "\t-dbtype nucl \\\n",
    "\t-title \"hilliam_pseudomonas_assemblies\" \\\n",
    "\t-out $blast_db/hilliam_assemblies\n",
    "\t\n",
    "```\n",
    "\n",
    "In the following script we will run BLAST+ to align the known PAGs to the genome assemblies from an external dataset (Hilliam-2017). Using the merged database created in the previous step, we run tblastn (protein to nucleotide)\n",
    "using as query (to search) sequences a fasta file containing the protein sequence for all PAGs. \n",
    "\n",
    "```sh\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --account=def-whsiao-ab\n",
    "#SBATCH --mem-per-cpu=4G #  GB of memory per cpu core\n",
    "#SBATCH --time=00:15:00\n",
    "#SBATCH --ntasks=1 # tasks in parallel\n",
    "#SBATCH --cpus-per-task=4 # CPU cores per task\n",
    "#SBATCH --job-name=\"blast_pags_hilliam\"\n",
    "#SBATCH --chdir=/scratch/mdprieto/\n",
    "#SBATCH --output=blast_pags_hilliam.out\n",
    "\n",
    "###########################################################################\n",
    "\n",
    "# load blast+ module\n",
    "module purge\n",
    "module load StdEnv/2020  gcc/9.3.0 blast+/2.12.0\n",
    "\t\n",
    "tblastn -query /home/mdprieto/git/hilliam_pseudomonas_2022/pags.fasta \\\n",
    "\t-db /scratch/mdprieto/results_hilliam/blastdb/hilliam_assemblies \\\n",
    "\t-show_gis \\\n",
    "\t-outfmt \"7\" \\\n",
    "\t-out /scratch/mdprieto/hilliam_blast_full.txt \\\n",
    "\t-evalue 1e-50 \\\n",
    "\t-num_threads 4 \\\n",
    "\t-max_hsps 1\n",
    "\n",
    "# blast of additional proteins by collaborator (Patrick)\n",
    "blastn \\\n",
    "\t-query /home/mdprieto/git/hilliam_pseudomonas_2022/patrick_pags.fasta \\\n",
    "\t-db /scratch/mdprieto/results_hilliam/blastdb/hilliam_assemblies \\\n",
    "\t-show_gis \\\n",
    "\t-outfmt \"7\" \\\n",
    "\t-out /scratch/mdprieto/patrick_blast.txt \\\n",
    "\t-evalue 1e-50 \\\n",
    "\t-num_threads 4 \\\n",
    "\t-max_hsps 1 \n",
    "```\n",
    "Finally, we move the results to our git repo directory and produce clean versions with headers.\n",
    "\n",
    "```sh\n",
    "# copy to git repo for project\n",
    "cd ~/scratch\n",
    "cp patrick_blast.txt hilliam_blast_full.txt ~/git/hilliam_pseudomonas_2022/results/\n",
    "\n",
    "# clean format and add headers\n",
    "cd ~/git/hilliam_pseudomonas_2022/results/\n",
    "grep --invert-match \"^#\" hilliam_blast_full.txt | \\\n",
    "\tsed '1s/^/qseqid\\tsseqid\\tpiden\\tlength\\tmismatch\\tgapopen\\tqstart\\tqend\\tsstart\\tsend\\tevalue\\tbitscore\\n/' \\\n",
    "\t> hilliam_blast_clean.txt\n",
    "\n",
    "grep --invert-match \"^#\" patrick_blast.txt | \\\n",
    "\tsed '1s/^/qseqid\\tsseqid\\tpiden\\tlength\\tmismatch\\tgapopen\\tqstart\\tqend\\tsstart\\tsend\\tevalue\\tbitscore\\n/' \\\n",
    "\t> patrick_blast_clean.txt\t\n",
    "\n",
    "```\n",
    "\n",
    "### Analysis of functional groups in BLAST hits\n",
    "\n",
    "To select optimal candidates for in-vitro evaluation in Aim2, we look for PAGs with transcriptional regulator activity among our hits. \n",
    "\n",
    "In our local machine, I set up the capacity to run multiple searches in `InterProScan` database. Requires installation of Java and running the `Install certificates.command` for our python version.\n",
    "\n",
    "Using `vim`, I pasted the IDs of the PAGs that were found in all the cohort (96 patients) and saved it in `list_pags_all_samples.txt`. Then, using the `seqtk` utility, I create a new fasta file including only these interesting proteins. \n",
    "\n",
    "```sh\n",
    "# work inside an environment and install dependencies\n",
    "conda create -name interpro\n",
    "conda activate interpro\n",
    "pip3 install xmltramp2 requests\n",
    "\n",
    "# install EMBI REST handler and interproscan script\n",
    "git clone https://github.com/ebi-wp/webservice-clients.git\n",
    "wget https://raw.githubusercontent.com/ebi-wp/webservice-clients/master/python/iprscan5.py\n",
    "\n",
    "# one liner to extract 30 sequences in a file (limit for InterPro)\n",
    "awk \"/^>/ {n++} n>30 {exit} {print}\" input_fasta > output_fasta\n",
    "\n",
    "# new fasta with only PAGs found in all patients\n",
    "seqtk subseq pags.fasta list_pags_all_samples.txt > pags_all_samples.fa\n",
    "\n",
    "# run search\n",
    "# options to output tsv, name output file, and reduce verbosity\n",
    "python3 iprscan5.py \\\n",
    "\t--sequence hilliam_pseudomonas_2022/pags_all_samples.fa \\\n",
    "\t--email azmigueldario@gmail.com \\\n",
    "\t--outformat tsv \\\n",
    "\t--outfile results_interpro.tsv \\\n",
    "\t--quiet &\n",
    "  \n",
    "# close environment once finished\n",
    "conda deactivate interpro\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3895dac5-d0b2-4a03-a807-84a27c15594a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52af57-9f08-4eb6-b4d7-e521bbb57264",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash [conda env:root] *",
   "language": "bash",
   "name": "conda-root-bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
